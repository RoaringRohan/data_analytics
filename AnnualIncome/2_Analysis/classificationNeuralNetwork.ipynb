{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0588bd2-6863-4a31-9ecc-f37475b49c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18cc4b4-13b4-4d44-9e2e-68f8b7b8692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "\n",
    "train_data = pd.read_csv('../1_Data/adult.data', header=None, names=columns, na_values=' ?', skipinitialspace=True)\n",
    "test_data = pd.read_csv('../1_Data/adult.test', header=0, names=columns, na_values=' ?', skipinitialspace=True, comment='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91cf2a1-409b-4b12-b306-ca48ac27feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['income'] = test_data['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "data_cleaned = pd.concat([train_data, test_data], axis=0).dropna().reset_index(drop=True)\n",
    "\n",
    "categorical_cols = [\n",
    "    'workclass', 'education', 'marital-status', 'occupation',\n",
    "    'relationship', 'race', 'sex', 'native-country'\n",
    "]\n",
    "data_encoded = pd.get_dummies(data_cleaned, columns=categorical_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "continuous_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "data_encoded[continuous_cols] = scaler.fit_transform(data_encoded[continuous_cols])\n",
    "\n",
    "data_encoded['income'] = data_encoded['income'].apply(lambda x: 1 if x.strip() == '>50K' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19926ae4-7aa5-4222-aa2e-1b3c4845a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_data.dropna())\n",
    "X_train = data_encoded.iloc[:train_size].drop(columns=['income']).values\n",
    "y_train = data_encoded.iloc[:train_size]['income'].values.reshape(-1, 1)\n",
    "X_test = data_encoded.iloc[train_size:].drop(columns=['income']).values\n",
    "y_test = data_encoded.iloc[train_size:]['income'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d9ebf7-e78c-4900-ad91-d90eebc3ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(42)\n",
    "    parameters = {}\n",
    "    for l in range(1, len(layer_dims)):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]).astype(np.float64) * np.sqrt(2. / layer_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1), dtype=np.float64)\n",
    "    return parameters\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return (Z > 0).astype(float)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    Z = np.array(Z, dtype=np.float64)  # Ensure Z is a NumPy array with correct dtype\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    caches = {}\n",
    "    A = np.array(X.T, dtype=np.float64)  # Ensure input is NumPy array with float64 type\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L):\n",
    "        Z = np.dot(parameters['W' + str(l)], A) + parameters['b' + str(l)]\n",
    "        A = relu(Z)\n",
    "        caches['A' + str(l)] = A\n",
    "        caches['Z' + str(l)] = Z\n",
    "    ZL = np.dot(parameters['W' + str(L)], A) + parameters['b' + str(L)]\n",
    "    AL = sigmoid(ZL)\n",
    "    caches['A' + str(L)] = AL\n",
    "    caches['Z' + str(L)] = ZL\n",
    "    return AL, caches\n",
    "\n",
    "def compute_loss(AL, Y):\n",
    "    m = Y.shape[0]\n",
    "    loss = -np.sum(Y.T * np.log(AL + 1e-8) + (1 - Y.T) * np.log(1 - AL + 1e-8)) / m\n",
    "    return np.squeeze(loss)\n",
    "\n",
    "def backward_propagation(X, Y, parameters, caches):\n",
    "    grads = {}\n",
    "    m = X.shape[0]\n",
    "    L = len(parameters) // 2\n",
    "    Y = Y.T\n",
    "    dZL = caches['A' + str(L)] - Y\n",
    "    grads['dW' + str(L)] = (1/m) * np.dot(dZL, caches['A' + str(L-1)].T).astype(np.float64)\n",
    "    grads['db' + str(L)] = (1/m) * np.sum(dZL, axis=1, keepdims=True).astype(np.float64)\n",
    "    for l in reversed(range(1, L)):\n",
    "        dA = np.dot(parameters['W' + str(l+1)].T, dZL)\n",
    "        dZ = dA * relu_derivative(caches['Z' + str(l)])\n",
    "        A_prev = X.T if l == 1 else caches['A' + str(l-1)]\n",
    "        grads['dW' + str(l)] = (1/m) * np.dot(dZ, A_prev.T).astype(np.float64)\n",
    "        grads['db' + str(l)] = (1/m) * np.sum(dZ, axis=1, keepdims=True).astype(np.float64)\n",
    "        dZL = dZ\n",
    "    return grads\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate, velocities, beta=0.9):\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L + 1):\n",
    "        velocities['dW' + str(l)] = beta * velocities['dW' + str(l)] + (1 - beta) * grads['dW' + str(l)]\n",
    "        velocities['db' + str(l)] = beta * velocities['db' + str(l)] + (1 - beta) * grads['db' + str(l)]\n",
    "        parameters['W' + str(l)] -= learning_rate * velocities['dW' + str(l)]\n",
    "        parameters['b' + str(l)] -= learning_rate * velocities['db' + str(l)]\n",
    "    return parameters, velocities\n",
    "\n",
    "def model(X, Y, layer_dims, learning_rate=0.01, epochs=20, batch_size=128):\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    velocities = {f'dW{l}': np.zeros_like(parameters[f'W{l}'], dtype=np.float64) for l in range(1, len(layer_dims))}\n",
    "    velocities.update({f'db{l}': np.zeros_like(parameters[f'b{l}'], dtype=np.float64) for l in range(1, len(layer_dims))})\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        permutation = np.random.permutation(X.shape[0])\n",
    "        X_shuffled, Y_shuffled = X[permutation], Y[permutation]\n",
    "\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch, Y_batch = X_shuffled[i:i+batch_size], Y_shuffled[i:i+batch_size]\n",
    "            AL, caches = forward_propagation(X_batch, parameters)\n",
    "            loss = compute_loss(AL, Y_batch)\n",
    "            grads = backward_propagation(X_batch, Y_batch, parameters, caches)\n",
    "            parameters, velocities = update_parameters(parameters, grads, learning_rate, velocities)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30e7022-2b5f-43a8-810d-5b37825fbefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/25, Loss: 0.3980\n",
      "Epoch 5/25, Loss: 0.2816\n",
      "Epoch 10/25, Loss: 0.2916\n",
      "Epoch 15/25, Loss: 0.4038\n",
      "Epoch 20/25, Loss: 0.2791\n",
      "Test Accuracy: 85.53%\n"
     ]
    }
   ],
   "source": [
    "layer_dims = [108, 64, 32, 16, 1]\n",
    "parameters_trained = model(X_train, y_train, layer_dims, learning_rate=0.01, epochs=25, batch_size=128)\n",
    "\n",
    "def predict(X, parameters):\n",
    "    AL, _ = forward_propagation(X, parameters)\n",
    "    predictions = (AL > 0.5).astype(int)\n",
    "    return predictions\n",
    "\n",
    "y_pred_test = predict(X_test, parameters_trained)\n",
    "accuracy_test = np.mean(y_pred_test.T == y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
